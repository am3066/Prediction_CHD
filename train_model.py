#import pandas as pd
#import numpy as np
#import pickle
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.decomposition import PCA
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report, make_scorer, recall_score
from imblearn.pipeline import Pipeline as ImbPipeline
from imblearn.over_sampling import SMOTE

# --- 1. Chargement des donnÃ©es et Nettoyage de 'famhist' ---
try:
    # Assurez-vous que le fichier CHDI.csv est dans le mÃªme dossier
    df = pd.read_csv("CHDI.csv", sep=';')
except FileNotFoundError:
    print("Erreur : Le fichier 'CHDI.csv' est introuvable. Veuillez vÃ©rifier le chemin.")
    exit()

# Harmonisation de la colonne catÃ©gorielle 'famhist'
if 'famhist' in df.columns:
    df['famhist'] = df['famhist'].astype(str).str.strip().str.lower().str.capitalize()
    # Remplacement des valeurs qui pourraient Ãªtre 'nan' (manquantes) ou autres
    # Si des NaN sont prÃ©sentes, elles seront gÃ©rÃ©es par le OneHotEncoder/ColumnTransformer
    # On peut les remplacer par 'Absent' si c'est la catÃ©gorie majoritaire ou les laisser
    # Le OneHotEncoder va les encoder s'il trouve 'Nan' comme catÃ©gorie.
    # Pour ce dataset spÃ©cifique, nous allons faire confiance Ã  l'imputer/encoder plus tard.

# --- 2. SÃ©paration des donnÃ©es ---
X = df.drop('chd', axis=1)
y = df['chd']

# Division stratifiÃ©e (important car 'chd' est dÃ©sÃ©quilibrÃ©e)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# --- 3. DÃ©finition des Pipelines de PrÃ©traitement ---
numerical_features = ['sbp', 'ldl', 'adiposity', 'obesity', 'age']
categorical_features = ['famhist']

# Pipeline NumÃ©rique (Imputation + Standardisation)
numerical_pipeline = Pipeline([
    # Imputation par la mÃ©diane (plus robuste aux outliers)
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
])

# Pipeline CatÃ©goriel (Encodage One-Hot)
categorical_pipeline = Pipeline([
    # Le OneHotEncoder va gÃ©rer les valeurs manquantes (NaN ou autres) en les traitant comme une catÃ©gorie
    # Nous ajoutons un imputer sur les catÃ©gories aussi, pour garantir que tout est gÃ©rÃ©.
    ('imputer_cat', SimpleImputer(strategy='constant', fill_value='Absent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))
])

# ColumnTransformer pour combiner les prÃ©traitements
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numerical_pipeline, numerical_features),
        ('cat', categorical_pipeline, categorical_features)
    ],
    remainder='drop'
)

# --- 4. DÃ©finition des ModÃ¨les et HyperparamÃ¨tres pour GridSearchCV ---
# Nous utilisons ImbPipeline pour inclure SMOTE avant le modÃ¨le
# SMOTE ne doit Ãªtre appliquÃ© que sur l'ensemble d'entraÃ®nement, ce que ImbPipeline assure.

# Le pipeline de base inclut PrÃ©traitement, ACP et SMOTE
base_pipeline_steps = [
    ('preprocessor', preprocessor),
    # On inclut SMOTE pour traiter le dÃ©sÃ©quilibre de 'chd'
    ('smote', SMOTE(random_state=42)), 
    ('pca', PCA(random_state=42))
]

# DÃ©finition des modÃ¨les et de leurs grilles d'hyperparamÃ¨tres
# 1. RÃ©gression Logistique (LR)
lr_pipeline = ImbPipeline(base_pipeline_steps + [('classifier', LogisticRegression(random_state=42, solver='liblinear'))])
lr_param_grid = {
    # PCA: nombre de composants Ã  conserver
    'pca__n_components': [3, 4, 5, 0.95], # 0.95 conserve 95% de la variance
    # LR: paramÃ¨tre de rÃ©gularisation C
    'classifier__C': [0.1, 1.0, 10.0]
}

# 2. K-Nearest Neighbors (KNN)
knn_pipeline = ImbPipeline(base_pipeline_steps + [('classifier', KNeighborsClassifier())])
knn_param_grid = {
    # PCA: nombre de composants Ã  conserver
    'pca__n_components': [3, 4, 5, 0.95],
    # KNN: nombre de voisins
    'classifier__n_neighbors': [5, 7, 9, 11]
}

# Liste des modÃ¨les Ã  tester
grids = [
    (lr_pipeline, lr_param_grid, 'LogisticRegression'),
    (knn_pipeline, knn_param_grid, 'KNeighborsClassifier')
]

# Nous utiliserons le recall (rappel) pour la classe positive (chd=1) 
# comme mÃ©trique principale, car nous voulons minimiser les faux nÃ©gatifs
# (ne pas dÃ©tecter une maladie existante), ce qui est crucial dans le domaine mÃ©dical.
scorer = make_scorer(recall_score, pos_label=1)

best_model = None
best_score = -1
best_name = ""

# --- 5. Optimisation des HyperparamÃ¨tres avec GridSearchCV ---
print("### DÃ©marrage de l'Optimisation des ModÃ¨les avec GridSearchCV... ###")

for pipeline, param_grid, name in grids:
    print(f"\n-> EntraÃ®nement et optimisation pour {name}...")
    
    # GridSearchCV pour trouver les meilleurs hyperparamÃ¨tres
    grid_search = GridSearchCV(
        estimator=pipeline, 
        param_grid=param_grid, 
        scoring=scorer, # Utilisation du Recall pour la sÃ©lection
        cv=5, 
        verbose=1, 
        n_jobs=-1 # Utiliser tous les cÅ“urs disponibles
    )
    
    # EntraÃ®nement sur les donnÃ©es
    grid_search.fit(X_train, y_train)
    
    # Ã‰valuation sur l'ensemble de test
    y_pred = grid_search.best_estimator_.predict(X_test)
    report = classification_report(y_test, y_pred)
    
    print(f"\n--- RÃ©sultats {name} ---")
    print(f"Meilleurs paramÃ¨tres: {grid_search.best_params_}")
    print(f"Score de validation (Recall): {grid_search.best_score_:.4f}")
    print(f"Rapport de classification sur l'ensemble de test :\n{report}")
    
    # Sauvegarde du meilleur modÃ¨le
    if grid_search.best_score_ > best_score:
        best_score = grid_search.best_score_
        best_model = grid_search.best_estimator_
        best_name = name

# --- 6. Sauvegarde du Meilleur ModÃ¨le ---
print(f"\n\nğŸ† Meilleur modÃ¨le sÃ©lectionnÃ© : {best_name} avec un Recall de {best_score:.4f}")
model_filename = 'Model.pkl'

# Sauvegarde de l'intÃ©gralitÃ© du pipeline optimisÃ© dans un fichier .pkl
with open(model_filename, 'wb') as file:
    pickle.dump(best_model, file)

print(f"âœ… Pipeline complet sauvegardÃ© dans {model_filename}")
